---
title: "What is a good way to measure the dispersion of growth curves?"
authors: "Justin Patterson, Elsa Beda"
output: pdf_document
---

```{r}
library("ggplot2")
library("mlegp")
library("deepgp")
```


```{r}
get_exp_data_with_error = function(max_t, b_0, b_1, b_2, e_0_extremeness, e_1_extremeness, e_2_extremeness) {
    # The model is y = (b_0 + e_0) + (b_1 + e_1)*exp((b_2 + e_2)*t)
    # where e_0, e_1 and e_2 are errors.
    # e_0_extremeness, e_1_extremeness & e_2_extremeness should be non-negative
    # with higher values indicating more extremeness.
    #
    # Returns y values.
    
    # R is 1-indexed. :(
    y = vector(mode = "numeric", length = max_t + 1)
    
    # It's some proportion of b_0
    sd_0 = e_0_extremeness * abs(b_0)
    e_0 = rnorm(n = max_t + 1, mean = 0, sd = sd_0)

    # Start large and decrease.
    # The part with (- e_1_extremeness * abs(b_1) / max_t)
    # is like the slope.
    sd_1 = e_1_extremeness * abs(b_1) + (- e_1_extremeness * abs(b_1) / max_t) * seq(0, max_t, 1)
    e_1 = rnorm(n = max_t + 1, mean = 0, sd = sd_1)

    sd_2 = e_2_extremeness * abs(b_2)
    e_2 = rnorm(n = max_t + 1, mean = 0, sd = sd_2)

    # y[1] means the y-value when t == 0.
    y[1] = round(b_0 + e_0[1] + b_1 + e_1[1])
    for (t in seq(2, max_t + 1, 1)) {
        y[t] = round((b_0 + e_0[t]) + (y[t - 1] - (b_0 + e_0[t]))*exp(b_2 + e_2[t]))
    }

    return(y)
}
```

```{r}
get_growth_data = function(
    num_curves,
    max_t, 
    b_0, 
    b_1, 
    b_2,
    e_0_extremeness,
    e_1_extremeness, 
    e_2_extremeness
) {
    # Before loop
    num_curves_without_extinction = 0
    # Call get_exp_data_with_error to fill g.
    num_rows = max_t + 1
    num_cols = num_curves
    g = matrix(
        data = numeric(length = num_rows * num_cols), 
        nrow = num_rows, 
        ncol = num_cols
    )
    while(num_curves_without_extinction < num_curves) {
        # We need to generate more growth curves.
        new_growth_curve = get_exp_data_with_error(
            max_t = max_t, 
            b_0 = b_0, 
            b_1 = b_1, 
            b_2 = b_2,
            e_0_extremeness = e_0_extremeness,
            e_1_extremeness = e_1_extremeness, 
            e_2_extremeness = e_2_extremeness
        )
        # Prep for next iteration.
        # If there was an extinction, then
        # do not increment num_curves_without_extinction;
        # otherwise, increment num_curves_without_extinction
        # and save the growth curve.

        # If there is at least 1 non-positive value,
        if(sum(new_growth_curve <= 0) > 0) {
            # There was an extinction.
            next 
        } else {
            num_curves_without_extinction = num_curves_without_extinction + 1
            # save curve
            g[, num_curves_without_extinction] = new_growth_curve
        }
    }

    return(g)
}
```

```{r}
get_sets_of_growth_data = function(
    num_sets,
    num_curves,
    max_t, 
    b_0, 
    b_1, 
    b_2,
    e_0_extremeness,
    e_1_extremeness, 
    e_2_extremeness
) {
    # Returns a list where each element of the list
    # is a matrix.  Columns in the matrices are
    # the data for the growth curves.
    return(
        replicate(
            n = num_sets,
            expr = get_growth_data(
                num_curves,
                max_t, 
                b_0, 
                b_1, 
                b_2,
                e_0_extremeness,
                e_1_extremeness, 
                e_2_extremeness
            ),
            simplify = FALSE
        )
    )
}
```

```{r}
max_t = 100
# Number of growth curves
NUM_REPLICATES_1 = 10

# Args for function call
num_curves = NUM_REPLICATES_1
b_0 = 500
b_1 = 100
b_2 = 0.09
e_0_extremeness = 0.9
e_1_extremeness = 0.2
e_2_extremeness = 0.9
num_sets = 2

try_2 = get_sets_of_growth_data(
    num_sets = num_sets,
    num_curves = num_curves,
    max_t = max_t, 
    b_0 = b_0, 
    b_1 = b_1, 
    b_2 = b_2,
    e_0_extremeness = e_0_extremeness,
    e_1_extremeness = e_1_extremeness, 
    e_2_extremeness = e_2_extremeness
)
```

```{r}
normalized_cv = function(x, na.rm = FALSE) {
    return(sd(x, na.rm) / median(x, na.rm))
}
```

```{r}
mean_normalized_cv_of_log_response = function(X) {
    # X: matrix
    #   The columns of X represent independent realizations
    #   of the same discrete-time postive integer-valued 
    #   stochastic process.
    #   The process is assumed to generate ratio data.
    #   Values in the same row of X have the same value
    #   of the index t for the stochastic process.
    #
    # The values in X are transformed via the log
    # function.  The standard deviation of each row
    # of X is computed and divided by the median of
    # each row to yield a normalized coefficient of 
    # variation (CV).
    # https://en.wikipedia.org/wiki/Coefficient_of_variation#Alternative  
    # The CVs of each row are summarized by taking
    # their arithmetic mean.

    return(1 / NROW(X) * sum(apply(X = log(X), MARGIN = 1, FUN = normalized_cv)))
}
```

```{r}
mean_normalized_cv_of_log_response(try_1)
```

Use a GP regression to estimate the variance at each time point.

```{r}
design_matrix = matrix(data = seq(0, NROW(try_1) - 1, 1), nrow = NROW(try_1), ncol = 1, byrow = FALSE)
try_1_mlegp = mlegp(X = design_matrix, Z = log(try_1))
```

```{r}
try_1_mlegp_predictions = mlegp::predict.gp(
    object = try_1_mlegp[[1]],
    se.fit = TRUE
)
```

```{r}
plot(try_1_mlegp)
```

```{r}
print(x = try_1_mlegp, nums = 1)
```

```{r}
mean(rcauchy(n = 3))
```

Try using the package deepgp. not

```{r}
theta_hat = mean_normalized_cv_of_log_response
```

```{r}
mle_var_of_estimator = function(theta_hat, X, m, ...) {
    # Estimates the variance of some estimator
    # theta_hat using m trials of the estimator
    # on samples of size n.
    # Args:
    #   theta_hat: 
    #   X: matrix of data
    #   m: number of replicates to use in estimating the
    #       variance of the estimator.
    #   ... (ellipses) Additional arguments to pass
    #       to theta_hat
    return(
        (1 / m) * sum((theta_hat(X) - (1 / m) * sum(theta_hat(X)))^2)
    )
}
```


```{r}
mle_var_of_estimator(theta_hat = theta_hat, X = try_1, m = 100000)
```

```{r}
g = try_1
g_data = data.frame(
    replicate_num = rep(seq_len(NCOL(g)), each = NROW(g)),
    year = rep(seq(0, NROW(g) - 1), times = NCOL(g)),
    log_pop_size = log(as.vector(g))
)
```

```{r}
fig = ggplot(
    data = g_data,
    mapping = aes(
        x = year,
        y = exp(log_pop_size),
        color = as.factor(replicate_num)
    )
) 

fig = fig + 
    geom_line() +
    labs(title = "Samples from the Same Stochastic Process", color = "Replicate")

fig

```


```{r}
png(filename = file.path("/home/justin/Documents/schoolwork/ISYE_6413_Design_of_Exp/doe_group_project/data/exp_growth.png"))
print(fig)
dev.off()
```