{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Population Size on an Earth-like Planet--a Computer Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sim_world_functions as swf\n",
    "\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pyarrow\n",
    "from scipy import stats\n",
    "from pert import PERT\n",
    "from shapely.geometry import Point\n",
    "import geopandas\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(swf)\n",
    "rng = np.random.default_rng()\n",
    "pl.Config.set_fmt_str_lengths(n=100)\n",
    "DATA_PATH = Path(\"../data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response variable is the arithmetic mean of the normalized coefficients of variation for the population sizes.\n",
    "\n",
    "$$\n",
    "z_{i} = \\frac{1}{T + 1}\n",
    "\\sum_{t=0}^{T}\n",
    "    \\frac{\n",
    "        \\sqrt{\n",
    "            \\hat{V} \\left(\n",
    "            \\mathrm{logpopsize}_{i,t}\n",
    "            \\right)\n",
    "        }\n",
    "    }\n",
    "    {\n",
    "        \\underset{j}{\\mathrm{median}}\\left(\\mathrm{logpopsize}_{i,j,t}\\right)\n",
    "    } \n",
    "         \n",
    "                \n",
    "$$\n",
    "\n",
    "where $i=1,2,\\dots,k$ indexes the treatment, $j=1,2,\\dots n_i$ indexes the replicate for the $i^{\\text{th}}$ treatment, and $t=1,2,\\dots,T$ indexes the time.\n",
    "\n",
    "$\\hat{V}$ denotes the unbiased sample variance which is taken of the natural logarithms of the population sizes observed for treatment $i$ at time $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic Balancing Equation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "x_{i,t} = b_{i, t-1} + \\sum_{j}{m_{j, i, t-1}} - \\sum_{j}{m_{i,j,t-1}} - d_{1, t-1}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x_{i,t} &= \\text{population size at location } i \\text{ at time } t\\\\\n",
    "b_{i, t-1} &= \\text{number of births at location } i \\text{ at time } t-1 \\\\\n",
    "m_{j, i, t-1} &= \\text{number of people immigrating to } i \\text{ from } j \\text{ at time } t-1 \\\\\n",
    "m_{i, j, t-1} &= \\text{number of people emigrating from } i \\text{ to } j \\text{ at time } t-1 \\\\\n",
    "d_{1, t-1} &= \\text{number of deaths at location } i \\text{ at time } t-1\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for the Entire Experiment\n",
    "SIMULATION_YEARS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data from Other Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL for distance matrix:\n",
    "dist_mat = np.loadtxt(Path(DATA_PATH, \"dist_matrix.csv\"), delimiter=\",\")\n",
    "# Set num_world_locations according to pre-made\n",
    "# dist_mat.\n",
    "num_world_locations = dist_mat.shape[0]\n",
    "# Manipulate dist_mat \n",
    "# https://stackoverflow.com/questions/16444930/copy-upper-triangle-to-lower-triangle-in-a-python-matrix\n",
    "dist_mat = np.triu(dist_mat)\n",
    "dist_mat = dist_mat + dist_mat.T\n",
    "np.fill_diagonal(a=dist_mat, val=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get geographic data that goes along with the distance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes 3 min on my computer.\n",
    "# https://ecoregions.appspot.com/\n",
    "ecoregions_2017_with_more_points = geopandas.read_file(filename=Path(DATA_PATH, \"ecoregions_2017_with_more_points.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to an equal-area CRS so that we can find\n",
    "# the areas of the ecoregions.\n",
    "# https://gis.stackexchange.com/questions/285266/geopandas-proj4-reproject-to-global-equal-area-projection\n",
    "ecoregions_2017_with_more_points.to_crs(crs=\"+proj=eck4 +lon_0=0 +x_0=0 +y_0=0 +datum=WGS84 +ellps=WGS84 +units=m +no_defs\", inplace=True)\n",
    "# Get the area of each ecoregion in square meters.\n",
    "ecoregions_2017_with_more_points[\"ecoregion_area_in_sq_m\"] = ecoregions_2017_with_more_points.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polars is way better than pandas!!!\n",
    "# Create a polars dataframe without the geometry info.\n",
    "# for performance reasons.\n",
    "ecoregions_2017_with_more_points_no_geo = pl.from_pandas(\n",
    "    data=ecoregions_2017_with_more_points.loc[:, [\"REALM\", \"BIOME_NAME\", \"ECO_NAME\", \"ecoregion_area_in_sq_m\"]]\n",
    ")\n",
    "\n",
    "ecoregions_2017_with_more_points_no_geo = (ecoregions_2017_with_more_points_no_geo\n",
    "    .sort([\"REALM\", \"BIOME_NAME\", \"ECO_NAME\"]) \n",
    "    .with_row_count(name=\"location\")\n",
    "    .with_columns([\n",
    "        # Convert the area of each ecoregion to square miles.\n",
    "        (pl.col(\"ecoregion_area_in_sq_m\") / (1609.34**2)).alias(\"ecoregion_area_in_sq_mi\"),\n",
    "\n",
    "        # Cast datatype for join later\n",
    "        pl.col(\"location\").cast(pl.Int64).alias(\"location\")\n",
    "    ])  \n",
    "    .drop(\"ecoregion_area_in_sq_m\")                                        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>location</th><th>REALM</th><th>BIOME_NAME</th><th>ECO_NAME</th><th>ecoregion_area_in_sq_mi</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>1465</td><td>&quot;Palearctic&quot;</td><td>&quot;Tundra&quot;</td><td>&quot;Trans-Baikal Bald Mountain tundra&quot;</td><td>84199.773149</td></tr><tr><td>1466</td><td>&quot;Palearctic&quot;</td><td>&quot;Tundra&quot;</td><td>&quot;Wrangel Island Arctic desert&quot;</td><td>2916.662085</td></tr><tr><td>1467</td><td>&quot;Palearctic&quot;</td><td>&quot;Tundra&quot;</td><td>&quot;Yamal-Gydan tundra&quot;</td><td>159486.350881</td></tr><tr><td>1468</td><td>&quot;Palearctic&quot;</td><td>&quot;Tundra&quot;</td><td>&quot;Yamal-Gydan tundra&quot;</td><td>159486.350881</td></tr><tr><td>1469</td><td>&quot;Palearctic&quot;</td><td>&quot;Tundra&quot;</td><td>&quot;Yamal-Gydan tundra&quot;</td><td>159486.350881</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────┬────────────┬────────────┬───────────────────────────────────┬─────────────────────────┐\n",
       "│ location ┆ REALM      ┆ BIOME_NAME ┆ ECO_NAME                          ┆ ecoregion_area_in_sq_mi │\n",
       "│ ---      ┆ ---        ┆ ---        ┆ ---                               ┆ ---                     │\n",
       "│ i64      ┆ str        ┆ str        ┆ str                               ┆ f64                     │\n",
       "╞══════════╪════════════╪════════════╪═══════════════════════════════════╪═════════════════════════╡\n",
       "│ 1465     ┆ Palearctic ┆ Tundra     ┆ Trans-Baikal Bald Mountain tundra ┆ 84199.773149            │\n",
       "│ 1466     ┆ Palearctic ┆ Tundra     ┆ Wrangel Island Arctic desert      ┆ 2916.662085             │\n",
       "│ 1467     ┆ Palearctic ┆ Tundra     ┆ Yamal-Gydan tundra                ┆ 159486.350881           │\n",
       "│ 1468     ┆ Palearctic ┆ Tundra     ┆ Yamal-Gydan tundra                ┆ 159486.350881           │\n",
       "│ 1469     ┆ Palearctic ┆ Tundra     ┆ Yamal-Gydan tundra                ┆ 159486.350881           │\n",
       "└──────────┴────────────┴────────────┴───────────────────────────────────┴─────────────────────────┘"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecoregions_2017_with_more_points_no_geo.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoregions_2017_with_more_points_no_geo.drop(\"ecoregion_area_in_sq_mi\").write_csv(file=Path(DATA_PATH, \"ecos.tsv\"), separator=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ecoregions_2017_with_more_points_no_geo to store data about each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the areas of each location\n",
    "# if each ecoregion in which they are located\n",
    "# is divided into equal area sections according\n",
    "# to the number of locations in that ecoregion?\n",
    "ecoregions_2017_with_more_points_no_geo = (ecoregions_2017_with_more_points_no_geo\n",
    "    .with_columns([\n",
    "        (pl.col(\"ecoregion_area_in_sq_mi\") / pl.count(\"ECO_NAME\").over(\"ECO_NAME\"))\n",
    "        .alias(\"location_area_in_sq_mi\")\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>location</th><th>REALM</th><th>BIOME_NAME</th><th>ECO_NAME</th><th>ecoregion_area_in_sq_mi</th><th>location_area_in_sq_mi</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1465</td><td>&quot;Palearctic&quot;</td><td>&quot;Tundra&quot;</td><td>&quot;Trans-Baikal Bald Mountain tundra&quot;</td><td>84199.773149</td><td>42099.886575</td></tr><tr><td>1466</td><td>&quot;Palearctic&quot;</td><td>&quot;Tundra&quot;</td><td>&quot;Wrangel Island Arctic desert&quot;</td><td>2916.662085</td><td>2916.662085</td></tr><tr><td>1467</td><td>&quot;Palearctic&quot;</td><td>&quot;Tundra&quot;</td><td>&quot;Yamal-Gydan tundra&quot;</td><td>159486.350881</td><td>53162.11696</td></tr><tr><td>1468</td><td>&quot;Palearctic&quot;</td><td>&quot;Tundra&quot;</td><td>&quot;Yamal-Gydan tundra&quot;</td><td>159486.350881</td><td>53162.11696</td></tr><tr><td>1469</td><td>&quot;Palearctic&quot;</td><td>&quot;Tundra&quot;</td><td>&quot;Yamal-Gydan tundra&quot;</td><td>159486.350881</td><td>53162.11696</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 6)\n",
       "┌──────────┬────────────┬────────────┬────────────────────┬────────────────────┬───────────────────┐\n",
       "│ location ┆ REALM      ┆ BIOME_NAME ┆ ECO_NAME           ┆ ecoregion_area_in_ ┆ location_area_in_ │\n",
       "│ ---      ┆ ---        ┆ ---        ┆ ---                ┆ sq_mi              ┆ sq_mi             │\n",
       "│ i64      ┆ str        ┆ str        ┆ str                ┆ ---                ┆ ---               │\n",
       "│          ┆            ┆            ┆                    ┆ f64                ┆ f64               │\n",
       "╞══════════╪════════════╪════════════╪════════════════════╪════════════════════╪═══════════════════╡\n",
       "│ 1465     ┆ Palearctic ┆ Tundra     ┆ Trans-Baikal Bald  ┆ 84199.773149       ┆ 42099.886575      │\n",
       "│          ┆            ┆            ┆ Mountain tundra    ┆                    ┆                   │\n",
       "│ 1466     ┆ Palearctic ┆ Tundra     ┆ Wrangel Island     ┆ 2916.662085        ┆ 2916.662085       │\n",
       "│          ┆            ┆            ┆ Arctic desert      ┆                    ┆                   │\n",
       "│ 1467     ┆ Palearctic ┆ Tundra     ┆ Yamal-Gydan tundra ┆ 159486.350881      ┆ 53162.11696       │\n",
       "│ 1468     ┆ Palearctic ┆ Tundra     ┆ Yamal-Gydan tundra ┆ 159486.350881      ┆ 53162.11696       │\n",
       "│ 1469     ┆ Palearctic ┆ Tundra     ┆ Yamal-Gydan tundra ┆ 159486.350881      ┆ 53162.11696       │\n",
       "└──────────┴────────────┴────────────┴────────────────────┴────────────────────┴───────────────────┘"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecoregions_2017_with_more_points_no_geo.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Planning Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This matrix was constructed in R.\n",
    "planning_matrix = pl.read_csv(\n",
    "    source=Path(DATA_PATH, \"planning_matrix.txt\"),\n",
    "    has_header=True,\n",
    "    separator=\" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>earth</th><th>location</th><th>REALM</th><th>BIOME_NAME</th><th>ECO_NAME</th><th>initial_agricultural_tech_level_in_use</th><th>initial_healthcare_tech_level_in_use</th><th>initial_housing_tech_level_in_use</th><th>initial_transportation_tech_level_in_use</th><th>initial_unaided_d_max_pop_density</th><th>initial_unaided_not_dt_max_pop_density</th><th>initial_unaided_t_max_pop_density</th><th>initial_warfare_tech_level_in_use</th><th>relevance_of_dist_based_on_transportation_tech_level</th><th>initial_pop_density_of_desert</th><th>initial_pop_density_of_tundra</th><th>initial_proportion_not_desert</th><th>initial_pop_density_ratio</th><th>initial_transition_probability_to_desert</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>0</td><td>&quot;Afrotropic&quot;</td><td>&quot;Deserts &amp; Xeric Shrublands&quot;</td><td>&quot;Aldabra Island xeric scrub&quot;</td><td>0.643977</td><td>0.000387</td><td>0.046324</td><td>0.161329</td><td>1.419058</td><td>6.43861</td><td>1.319</td><td>0.061229</td><td>1768.624322</td><td>0.220119</td><td>0.238211</td><td>0.88836</td><td>777.047765</td><td>0.004062</td></tr><tr><td>1</td><td>1</td><td>&quot;Afrotropic&quot;</td><td>&quot;Deserts &amp; Xeric Shrublands&quot;</td><td>&quot;Djibouti xeric shrublands&quot;</td><td>0.662884</td><td>0.08286</td><td>0.321868</td><td>0.341016</td><td>0.473389</td><td>8.203317</td><td>1.713027</td><td>0.027305</td><td>-1228.728912</td><td>0.220119</td><td>0.238211</td><td>0.88836</td><td>777.047765</td><td>0.004062</td></tr><tr><td>1</td><td>2</td><td>&quot;Afrotropic&quot;</td><td>&quot;Deserts &amp; Xeric Shrublands&quot;</td><td>&quot;Eritrean coastal desert&quot;</td><td>0.63524</td><td>0.021075</td><td>0.230545</td><td>0.153925</td><td>1.6928435</td><td>5.129825</td><td>1.0713665</td><td>0.087405</td><td>-609.0</td><td>0.220119</td><td>0.238211</td><td>0.88836</td><td>777.047765</td><td>0.004062</td></tr><tr><td>1</td><td>3</td><td>&quot;Afrotropic&quot;</td><td>&quot;Deserts &amp; Xeric Shrublands&quot;</td><td>&quot;Gariep Karoo&quot;</td><td>0.63524</td><td>0.021075</td><td>0.230545</td><td>0.153925</td><td>1.6928435</td><td>5.129825</td><td>1.0713665</td><td>0.087405</td><td>-609.0</td><td>0.220119</td><td>0.238211</td><td>0.88836</td><td>777.047765</td><td>0.004062</td></tr><tr><td>1</td><td>4</td><td>&quot;Afrotropic&quot;</td><td>&quot;Deserts &amp; Xeric Shrublands&quot;</td><td>&quot;Gariep Karoo&quot;</td><td>0.63524</td><td>0.021075</td><td>0.230545</td><td>0.153925</td><td>1.6928435</td><td>5.129825</td><td>1.0713665</td><td>0.087405</td><td>-609.0</td><td>0.220119</td><td>0.238211</td><td>0.88836</td><td>777.047765</td><td>0.004062</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 19)\n",
       "┌───────┬──────────┬────────────┬────────────┬───┬────────────┬────────────┬───────────┬───────────┐\n",
       "│ earth ┆ location ┆ REALM      ┆ BIOME_NAME ┆ … ┆ initial_po ┆ initial_pr ┆ initial_p ┆ initial_t │\n",
       "│ ---   ┆ ---      ┆ ---        ┆ ---        ┆   ┆ p_density_ ┆ oportion_n ┆ op_densit ┆ ransition │\n",
       "│ i64   ┆ i64      ┆ str        ┆ str        ┆   ┆ of_tundra  ┆ ot_desert  ┆ y_ratio   ┆ _probabil │\n",
       "│       ┆          ┆            ┆            ┆   ┆ ---        ┆ ---        ┆ ---       ┆ ity_to_de │\n",
       "│       ┆          ┆            ┆            ┆   ┆ f64        ┆ f64        ┆ f64       ┆ sert      │\n",
       "│       ┆          ┆            ┆            ┆   ┆            ┆            ┆           ┆ ---       │\n",
       "│       ┆          ┆            ┆            ┆   ┆            ┆            ┆           ┆ f64       │\n",
       "╞═══════╪══════════╪════════════╪════════════╪═══╪════════════╪════════════╪═══════════╪═══════════╡\n",
       "│ 1     ┆ 0        ┆ Afrotropic ┆ Deserts &  ┆ … ┆ 0.238211   ┆ 0.88836    ┆ 777.04776 ┆ 0.004062  │\n",
       "│       ┆          ┆            ┆ Xeric      ┆   ┆            ┆            ┆ 5         ┆           │\n",
       "│       ┆          ┆            ┆ Shrublands ┆   ┆            ┆            ┆           ┆           │\n",
       "│ 1     ┆ 1        ┆ Afrotropic ┆ Deserts &  ┆ … ┆ 0.238211   ┆ 0.88836    ┆ 777.04776 ┆ 0.004062  │\n",
       "│       ┆          ┆            ┆ Xeric      ┆   ┆            ┆            ┆ 5         ┆           │\n",
       "│       ┆          ┆            ┆ Shrublands ┆   ┆            ┆            ┆           ┆           │\n",
       "│ 1     ┆ 2        ┆ Afrotropic ┆ Deserts &  ┆ … ┆ 0.238211   ┆ 0.88836    ┆ 777.04776 ┆ 0.004062  │\n",
       "│       ┆          ┆            ┆ Xeric      ┆   ┆            ┆            ┆ 5         ┆           │\n",
       "│       ┆          ┆            ┆ Shrublands ┆   ┆            ┆            ┆           ┆           │\n",
       "│ 1     ┆ 3        ┆ Afrotropic ┆ Deserts &  ┆ … ┆ 0.238211   ┆ 0.88836    ┆ 777.04776 ┆ 0.004062  │\n",
       "│       ┆          ┆            ┆ Xeric      ┆   ┆            ┆            ┆ 5         ┆           │\n",
       "│       ┆          ┆            ┆ Shrublands ┆   ┆            ┆            ┆           ┆           │\n",
       "│ 1     ┆ 4        ┆ Afrotropic ┆ Deserts &  ┆ … ┆ 0.238211   ┆ 0.88836    ┆ 777.04776 ┆ 0.004062  │\n",
       "│       ┆          ┆            ┆ Xeric      ┆   ┆            ┆            ┆ 5         ┆           │\n",
       "│       ┆          ┆            ┆ Shrublands ┆   ┆            ┆            ┆           ┆           │\n",
       "└───────┴──────────┴────────────┴────────────┴───┴────────────┴────────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planning_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Complete Graph and Initialize it With Starting Attributes for Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_world = nx.complete_graph(num_world_locations)\n",
    "# We'll use this to filter now instead\n",
    "# of having to repeatedly filter later.\n",
    "what_earth_we_on = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ed stands for earth data\n",
    "ed = (planning_matrix\n",
    "    .filter(pl.col(\"earth\") == what_earth_we_on)\n",
    "    # Drop them now because we'll pick them up again\n",
    "    # via the join.\n",
    "    .drop([\"REALM\",\t\"BIOME_NAME\", \"ECO_NAME\"])\n",
    "    .join(\n",
    "        other=ecoregions_2017_with_more_points_no_geo,\n",
    "        how=\"inner\",\n",
    "        on=\"location\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Get ecoregions that were not in desert before.\n",
    "##############################################\n",
    "\n",
    "unique_ecos_within_deserts_within_realm = (ed\n",
    "    .filter(pl.col(\"BIOME_NAME\") == \"Deserts & Xeric Shrublands\")\n",
    "    .select(\n",
    "        pl.col(\"REALM\"), \n",
    "        pl.col(\"ECO_NAME\").alias(\"unique_ecos_within_deserts_within_realm\")\n",
    "    )\n",
    "    .unique()\n",
    "    .sort(by=\"REALM\")\n",
    "    # https://stackoverflow.com/a/70061932/8423001\n",
    "    .with_columns([\n",
    "        pl.lit(1).alias(\"ones_counter\")\n",
    "    ])\n",
    "    .select(\n",
    "        pl.all().exclude(\"ones_counter\"),\n",
    "        pl.col(\"ones_counter\").cum_sum().over(\"REALM\").alias(\"unique_ecos_within_deserts_within_realm_id\")\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "num_unique_ecos_within_deserts_within_realm = (ed\n",
    "    .filter(pl.col(\"BIOME_NAME\") == \"Deserts & Xeric Shrublands\")\n",
    "    .select(\n",
    "        pl.col(\"REALM\"), \n",
    "        (pl.col(\"ECO_NAME\").unique().count()).over(\"REALM\").alias(\"num_unique_ecos_within_deserts_within_realm\")\n",
    "    )\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "u = (num_unique_ecos_within_deserts_within_realm\n",
    "    .join(\n",
    "        other=ed,\n",
    "        on=\"REALM\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    .with_columns([\n",
    "        (\n",
    "            pl.col(\"num_unique_ecos_within_deserts_within_realm\") * pl.col(\"initial_proportion_not_desert\")\n",
    "        )\n",
    "        .round()\n",
    "        .cast(pl.Int64)\n",
    "        .alias(\"num_unique_ecos_within_deserts_within_realm_to_un_desert\")\n",
    "    ])\n",
    "    .select([\n",
    "        \"REALM\",\n",
    "        \"num_unique_ecos_within_deserts_within_realm\",\n",
    "        \"num_unique_ecos_within_deserts_within_realm_to_un_desert\"\n",
    "    ])\n",
    "    .unique(subset=\"REALM\")\n",
    ")\n",
    "\n",
    "ecos_to_un_desert = pl.Series(name=\"ecos_to_un_desert\", dtype=pl.Utf8)\n",
    "for realm, num_unique_ecos_within_deserts_within_realm, num_unique_ecos_within_deserts_within_realm_to_un_desert in u.iter_rows():\n",
    "    # These are the indices of unique ecoregions\n",
    "    # to un-desert.\n",
    "    indices_to_un_desert = rng.choice(\n",
    "        a=np.arange(start=1, stop=num_unique_ecos_within_deserts_within_realm + 1, step=1), \n",
    "        size=num_unique_ecos_within_deserts_within_realm_to_un_desert,\n",
    "        replace=False\n",
    "    )\n",
    "    \n",
    "    indices_to_un_desert.sort()\n",
    "\n",
    "    ecos_to_un_desert.append(unique_ecos_within_deserts_within_realm\n",
    "        .filter(\n",
    "            (pl.col(\"REALM\") == realm)\n",
    "            & (pl.col(\"unique_ecos_within_deserts_within_realm_id\").is_in(indices_to_un_desert))\n",
    "        )\n",
    "        .select(\"unique_ecos_within_deserts_within_realm\")\n",
    "        .to_series()\n",
    "    )\n",
    "\n",
    "# Do the un-deserting.\n",
    "prior_biomes = swf.prior_biomes_before_desertification(len(ecos_to_un_desert), rng)\n",
    "\n",
    "desertification = pl.DataFrame(\n",
    "    data={\n",
    "        \"eco_to_un_desert\": ecos_to_un_desert,\n",
    "        \"prior_biome\": prior_biomes\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make edge weights between the world locations\n",
    "# to represent the distance between those locations.\n",
    "# https://stackoverflow.com/questions/17051589/parsing-through-edges-in-networkx-graph\n",
    "for (v1, v2, weight) in pre_world.edges.data('weight'):\n",
    "    # https://trenton3983.github.io/files/projects/2020-05-21_intro_to_network_analysis_in_python/2020-05-21_intro_to_network_analysis_in_python.html\n",
    "    # https://stackoverflow.com/questions/40128692/networkx-how-to-add-weights-to-an-existing-g-edges\n",
    "\n",
    "    pre_world[v1][v2][\"weight\"] = dist_mat[v1, v2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update initial node attributes\n",
    "pre_world_node_attributes = {}\n",
    "# Handle desertification first.\n",
    "for node_id in range(num_world_locations):\n",
    "    # Are we in a location within an ecoregion\n",
    "    # that needs to be un-deserted?\n",
    "    eco = ed[node_id, \"ECO_NAME\"]\n",
    "    actual_biome = ed[node_id, \"BIOME_NAME\"]\n",
    "    if eco in ecos_to_un_desert:\n",
    "        # un-desert\n",
    "        actual_biome = (desertification\n",
    "            .filter(pl.col(\"eco_to_un_desert\") == eco)\n",
    "            .select(\"prior_biome\")\n",
    "            .item()\n",
    "        )\n",
    "    pre_world_node_attributes[node_id] = {\n",
    "        # Are we in a location within an ecoregion\n",
    "        # that needs to be un-deserted?\n",
    "        \"actual_biome\": actual_biome\n",
    "    }\n",
    "# Set our node attributes.\n",
    "# https://stackoverflow.com/questions/53508805/simple-way-for-modifying-attributes-of-single-nodes-in-networkx-2-1?rq=3\n",
    "nx.set_node_attributes(pre_world, pre_world_node_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, update other initial node attributes\n",
    "for node_id in range(num_world_locations):\n",
    "    # Set the pop_size attribute.\n",
    "    if pre_world_node_attributes[node_id][\"actual_biome\"] == \"Deserts & Xeric Shrublands\":\n",
    "        pre_world_node_attributes[node_id] = {\n",
    "            \"pop_size\": round(cep[node_id, \"initial_pop_density_of_desert\"] \\\n",
    "                * ecoregions_2017_with_more_points_no_geo[node_id, \"location_area_in_sq_mi\"])\n",
    "        }\n",
    "    elif pre_world_node_attributes[node_id][\"actual_biome\"] == \"Tundra\":\n",
    "        pre_world_node_attributes[node_id] = {\n",
    "            \"pop_size\": round(cep[node_id, \"initial_pop_density_of_tundra\"] \\\n",
    "                * ecoregions_2017_with_more_points_no_geo[node_id, \"location_area_in_sq_mi\"]) \n",
    "        }\n",
    "    else:\n",
    "        # We are at a location where the pop_size depends\n",
    "        # on the mean of initial_pop_density_of_desert and initial_pop_density_of_tundra.\n",
    "        mean_uninhabitable_initial_pop_density = (\n",
    "            cep[node_id, \"initial_pop_density_of_desert\"] \\\n",
    "                + cep[node_id, \"initial_pop_density_of_tundra\"]\n",
    "            ) / 2\n",
    "        \n",
    "        pre_world_node_attributes[node_id] = {\n",
    "            \"pop_size\": round(cep[node_id, \"initial_pop_density_ratio\"] \\\n",
    "                * mean_uninhabitable_initial_pop_density \\\n",
    "                * ecoregions_2017_with_more_points_no_geo[node_id, \"location_area_in_sq_mi\"])\n",
    "        }\n",
    "        \n",
    "        # \"pop_size\": treatments[node_id, \"initial_pop_size\"], \n",
    "        # \"carrying_capacity\": treatments[node_id, \"initial_unaided_carrying_cap\"],\n",
    "        # \"transportation_technology_level_in_use\": INITIAL_TRANSPORTATION_TECH_LEVEL_IN_USE.rvs().item(),\n",
    "        # \"sortino_ratio\": 0.5,\n",
    "        # # 0 = no knowledge\n",
    "        # # 1 = perfect knowledge\n",
    "        # \"knowledge_of_neighbors\": np.zeros(shape=num_world_locations),\n",
    "        # # calculate this as a softargmax of sortino ratios \n",
    "        # \"proportion_desirous_to_emigrate\": 0.2,\n",
    "        # \"emigration_success_rate\": 0.5,\n",
    "        # \"energy_hills_to_neighbors\": np.zeros(shape=num_world_locations)\n",
    "    # }\n",
    "    # for neighbor in pre_world.neighbors(node_id):\n",
    "    #     # Calculate stuff we need to store in the current \n",
    "    #     # node in relation to its neighbors.\n",
    "    #     relevance_of_dist = swf.weight_0_more(\n",
    "    #         x=pre_world_node_attributes[node_id][\"transportation_technology_level_in_use\"],\n",
    "    #         b=RELEVANCE_OF_DIST_BASED_ON_TRANSPORTATION_TECH_LEVEL\n",
    "    #     )\n",
    "    #     energy_hill_to_neighbor = relevance_of_dist * pre_world[node_id][neighbor][\"weight\"] \n",
    "    #     # Add info. to attribute dict for node_id.\n",
    "    #     pre_world_node_attributes[node_id][\"energy_hills_to_neighbors\"][neighbor] = energy_hill_to_neighbor\n",
    "\n",
    "# Update our node attributes.\n",
    "# https://stackoverflow.com/questions/53508805/simple-way-for-modifying-attributes-of-single-nodes-in-networkx-2-1?rq=3\n",
    "nx.set_node_attributes(pre_world, pre_world_node_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actual_biome': 'Flooded Grasslands & Savannas', 'pop_size': 926693}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_world.nodes[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test looping structure\n",
    "# https://stackoverflow.com/questions/53508805/simple-way-for-modifying-attributes-of-single-nodes-in-networkx-2-1?rq=3\n",
    "for t in range(SIMULATION_YEARS):\n",
    "    for node_id in range(num_world_locations):\n",
    "        carrying_cap = pre_world_node_attributes[node_id][\"carrying_capacity\"]\n",
    "        pop_size = pre_world_node_attributes[node_id][\"pop_size\"]\n",
    "\n",
    "        pre_world_node_attributes[node_id][\"pop_size\"] = swf.logistic_growth(\n",
    "            previous_pop=pop_size,\n",
    "            r=0.05,\n",
    "            carrying_cap=carrying_cap\n",
    "        )\n",
    "        \n",
    "        \n",
    "# Set our node attributes.\n",
    "nx.set_node_attributes(pre_world, pre_world_node_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_world_betweenness_centralities = nx.betweenness_centrality(\n",
    "    G=pre_world,\n",
    "    weight=\"weight\"\n",
    ")\n",
    "\n",
    "pre_biomes_betweenness_centralities = nx.betweenness_centrality(\n",
    "    G=pre_biomes\n",
    ")\n",
    "\n",
    "# Get a node with a maximal betweenness centrality.\n",
    "# This node will hold our starting population.\n",
    "# https://stackoverflow.com/a/280156/8423001\n",
    "starting_node = max(\n",
    "    pre_world_betweenness_centralities, \n",
    "    key=pre_world_betweenness_centralities.get\n",
    ")\n",
    "\n",
    "starting_node_biome_id = max(\n",
    "    pre_biomes_betweenness_centralities, \n",
    "    key=pre_biomes_betweenness_centralities.get\n",
    ")\n",
    "\n",
    "starting_node_biome = BIOMES[starting_node_biome_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(pre_biomes_betweenness_centralities.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/3071441/8423001\n",
    "(\n",
    "    stats.rankdata(\n",
    "        a=list(pre_biomes_betweenness_centralities.values()),\n",
    "        method=\"dense\"\n",
    "    )\n",
    "    # Because the ranks start at 1 but Python is 0-indexed,\n",
    "    # subtract 1.\n",
    "    - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.array(list(pre_biomes_betweenness_centralities.values())) <= 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.rankdata(\n",
    "        a=[-2, 0, 3, 3, 3],\n",
    "        method=\"max\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stochastic_func(\n",
    "#     x,\n",
    "#     b,\n",
    "#     corr\n",
    "# ):\n",
    "#     rng = np.random.default_rng()\n",
    "#     std_x = np.std(x)\n",
    "#     if std_x == 0:\n",
    "#         y = rng.choice(np.arange(b + 1))\n",
    "#     else:\n",
    "#         x_normalized = (x - np.mean(x))/np.std(x)\n",
    " \n",
    "#         y_normalized = corr * x_normalized\n",
    "#         std_ints = np.std(np.arange(b + 1))\n",
    "#         mean_ints = (1 + b)/2\n",
    "#         y = y_normalized * std_ints + mean_ints\n",
    "#     return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copula Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_copula(*args, **kwargs):\n",
    "    \"\"\"Get the value of a Gaussian Copula.\"\"\"\n",
    "    # https://en.wikipedia.org/wiki/Copula_(probability_theory)#Gaussian_copula\n",
    "    # Arguments provided via position should be \n",
    "    # real numbers in [0, 1].  \n",
    "    # kwargs should contain a key=value combination\n",
    "    # where the key is cov.\n",
    "    #\n",
    "    # The multivariate_normal.cdf returns nan when the corresponding\n",
    "    # probability law is at least two dimensional and at least one of \n",
    "    # the values supplied to x is -inf.  However, we think that it is\n",
    "    # reasonable for it just to return 0 instead of nan.\n",
    "    x = stats.norm.ppf(q=args)\n",
    "    if (x == float(\"-inf\")).any():\n",
    "        cdf = 0\n",
    "    else:\n",
    "        cdf = stats.multivariate_normal.cdf(\n",
    "            x=stats.norm.ppf(q=args),\n",
    "            mean=np.zeros(shape=len(args)),\n",
    "            allow_singular=True,\n",
    "            **kwargs      \n",
    "        )\n",
    "\n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bivariate_discrete_copula_pmf(C, u:int, v:int, R:int, S:int, **kwargs) -> float:\n",
    "    \"\"\"Get the value of the probability mass function\n",
    "    at (u, v) using the copula function C.\n",
    "\n",
    "    source: https://doi.org/10.1515/demo-2020-0022\n",
    "    see: equation 7.1\n",
    "    \"\"\"\n",
    "    if (u < 0) or (u > (R - 1)):\n",
    "        raise ValueError(\"u must be in {0, 1, ..., R - 1}\")\n",
    "    if (v < 0) or (v > (S - 1)):\n",
    "        raise ValueError(\"v must be in {0, 1, ..., S - 1}\")\n",
    "\n",
    "    pmf = C((u + 1)/R, (v + 1)/S, **kwargs) \\\n",
    "        - C(u/R, (v + 1)/S, **kwargs) \\\n",
    "        - C((u + 1)/R, v/S, **kwargs) \\\n",
    "        + C(u/R, v/S, **kwargs)\n",
    "    \n",
    "    if (pmf < (0 - sys.float_info.epsilon)) or (pmf > (1 + sys.float_info.epsilon)):\n",
    "        raise RuntimeError(\"C appears to be an invalid copula.\")\n",
    "    \n",
    "    return pmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_conditional_pmf(C, R:int, S:int, **kwargs):\n",
    "    \"\"\"Make conditional PMF array.  \n",
    "    \n",
    "    For all u in {0, 1, ..., R - 1},\n",
    "    determine the conditional distribution:\n",
    "    P(V=v|U=u).\n",
    "    Save this as a two-dimensional array\n",
    "    where the (i, j) entry in the array\n",
    "    represents P(V=j|U=i).\n",
    "\n",
    "    Args:\n",
    "        C: function. This is the function for a copula.\n",
    "\n",
    "        **kwargs: additional name=value pairs that can\n",
    "            be passed to C.\n",
    "  \n",
    "    Returns:\n",
    "        numpy.ndarray.    \n",
    "    \"\"\"\n",
    "    \n",
    "    conditional_pmf_array = np.empty(shape=(R, S))\n",
    "    for u in range(R):\n",
    "        for v in range(S):\n",
    "            # Save a preliminary value.\n",
    "            conditional_pmf_array[u, v] = bivariate_discrete_copula_pmf(\n",
    "                C=gaussian_copula, \n",
    "                u=u, \n",
    "                v=v, \n",
    "                R=R, \n",
    "                S=S, \n",
    "                **kwargs\n",
    "            )\n",
    "        # Now, after getting part of the array filled out,\n",
    "        # do some rescaling to make sure we are\n",
    "        # constructing a valid probability distribution.\n",
    "        probs_as_ints = (conditional_pmf_array[u, :] * (2 ** (32 - 1))).astype(np.int32)\n",
    "        probs_as_probs = (probs_as_ints / probs_as_ints.sum())\n",
    "        conditional_pmf_array[u, :] = probs_as_probs\n",
    "\n",
    "    return conditional_pmf_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_biomes = len(BIOMES)\n",
    "corr = np.array([\n",
    "    [1, 0.9],\n",
    "    [0.9, 1]\n",
    "])\n",
    "\n",
    "conditional_pmf = make_conditional_pmf(\n",
    "    C=gaussian_copula,\n",
    "    R=NUM_WORLD_LOCATIONS,\n",
    "    S=num_biomes,\n",
    "    cov=corr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlated_ranks(\n",
    "    conditional_pmf,\n",
    "    rng\n",
    "):\n",
    "    \"\"\"Given a bivariate conditional_pmf formatted\n",
    "    as an array, return 0-index-based ranks.\n",
    "\n",
    "    Args:\n",
    "        conditional_pmf: numpy.ndarray\n",
    "        rng: numpy.random._generator.Generator\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray. The order of the elements\n",
    "        in the 1-dimensional array is significant.\n",
    "    \"\"\"\n",
    "    conditional_pmf_shape = conditional_pmf.shape\n",
    "    num_x_ranks = conditional_pmf_shape[0]\n",
    "    num_y_ranks = conditional_pmf_shape[1]\n",
    "\n",
    "    if num_x_ranks < num_y_ranks:\n",
    "        raise NotImplementedError(\n",
    "\"num_y_ranks must be <= num_x_ranks\\n \\\n",
    "Please make sure that conditional_pmf has a \\\n",
    "number of rows greater than or equal to its \\\n",
    "number of columns.  Also, make sure that \\\n",
    "each row is a valid probability distribution.\"\n",
    "        )  \n",
    "      \n",
    "    y_ranks = np.empty(shape=num_x_ranks, dtype=int)\n",
    "    \n",
    "    # Before loop\n",
    "    is_surjective = False\n",
    "\n",
    "    # Repeatedly generate possible realizations of \n",
    "    # ranks for the Y random variable\n",
    "    # until surjectivity is achieved.\n",
    "    while is_surjective is False:\n",
    "        for x_rank in range(num_x_ranks):\n",
    "            # Choose y_ranks[x_rank] based on \n",
    "            # the conditional PMF for \n",
    "            # the current value of x_rank.\n",
    "            y_ranks[x_rank] = rng.choice(\n",
    "                # Choose from all of the possible\n",
    "                # Y ranks.\n",
    "                a=num_y_ranks, \n",
    "                # Weight the choice according to\n",
    "                # the conditional_pmf.\n",
    "                p=conditional_pmf[x_rank, :], \n",
    "                size=1,\n",
    "                replace=True,\n",
    "                shuffle=False\n",
    "            ).item()\n",
    "\n",
    "        # Test for surjectivity after building out y_ranks\n",
    "        is_surjective = bool(\n",
    "            np.isin(\n",
    "                element=np.arange(num_y_ranks), \n",
    "                test_elements=y_ranks\n",
    "            ).all()\n",
    "        )\n",
    "\n",
    "    return y_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biome_indices_for_world_locations = get_correlated_ranks(\n",
    "    conditional_pmf=conditional_pmf,\n",
    "    rng=rng\n",
    ")\n",
    "\n",
    "biomes_for_world_locations = [BIOMES[b] for b in biome_indices_for_world_locations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://realpython.com/iterate-through-dictionary-python/#iterating-through-dictionaries-comprehension-examples\n",
    "{n: {\"biome\": biomes_for_world_locations[n]} for n in range(NUM_WORLD_LOCATIONS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plan on assigning biomes to the nodes in our world.\n",
    "# But, we must consider that some biomes are more likely\n",
    "# to be connected.  Thus, we assign the biomes randomly\n",
    "# while taking account of the betweenness centralities.\n",
    "# With probability 0.5, we assign neighbors the same\n",
    "# biome, while with probability 0.5, we assign neighbors\n",
    "# a new biome of similar betweenness centrality.\n",
    "1.0 / NUM_WORLD_LOCATIONS\n",
    "sorted(pre_biomes_betweenness_centralities.values())\n",
    "# Given a value of the ECDF of pre_world_betweenness_centralities\n",
    "# generate an appropriately positioned random rank\n",
    "# within pre_biomes_betweenness_centralities.\n",
    "# First, rank the pre_world_betweenness_centralities.\n",
    "sorted(pre_world_betweenness_centralities.values())\n",
    "# Second, find the find the value of the ECDF for each rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(\n",
    "    a=list(pre_world_betweenness_centralities.values()),\n",
    "    q=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in pre_biomes.neighbors(starting_node_biome_id):\n",
    "    print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through nodes and set initial parameters.\n",
    "for node in nx.nodes(G=pre_world):\n",
    "    nx.set_node_attributes(\n",
    "        G=pre_world, \n",
    "        # https://realpython.com/iterate-through-dictionary-python/#iterating-through-dictionaries-comprehension-examples\n",
    "        values={n: {\"biome\": biomes_for_world_locations[n]} for n in range(NUM_WORLD_LOCATIONS)}\n",
    "        # {\n",
    "        #     node: {\"carrying_capacity\": 1000000},\n",
    "        # }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/WestHealth/pyvis/issues/48\n",
    "world_layout = nx.spring_layout(G=pre_world, iterations=1, threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.from_nx(nx_graph=pre_world, show_edge_weights=True)\n",
    "for node in world.nodes:\n",
    "    node[\"x\"] = world_layout[node[\"id\"]][0] * 1000\n",
    "    node[\"y\"] = world_layout[node[\"id\"]][1] * 1000\n",
    "world.toggle_physics(False)\n",
    "world.show(\"fast_world.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.from_nx(nx_graph=pre_world, show_edge_weights=True)\n",
    "world.show(\"world.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doe_group_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
