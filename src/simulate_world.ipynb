{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Population Size on an Earth-like Planet--a Computer Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pert import PERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response variable is total population size after SIMULATION_YEARS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL_AVG_CARRYING_CAPACITY_PER_LOCATION: 11453780.0\n"
     ]
    }
   ],
   "source": [
    "NUM_WORLD_LOCATIONS = 100\n",
    "SIMULATION_YEARS = 10000\n",
    "INITIAL_POPULATION_PROPORTION = 0.0001\n",
    "# square miles \n",
    "TOTAL_LAND_AREA = 57268900 \n",
    "# The average maximum sustainable population density \n",
    "# (per square mile) on the planet for a hunter-gatherer society.\n",
    "# https://en.wikipedia.org/wiki/Hunter-gatherer#:~:text=One%20group%2C%20the%20Chumash%2C%20had,21.6%20persons%20per%20square%20mile.\n",
    "INITIAL_MAX_POP_DENSITY = 20\n",
    "INITIAL_AVG_CARRYING_CAPACITY_PER_LOCATION = (INITIAL_MAX_POP_DENSITY * TOTAL_LAND_AREA) / NUM_WORLD_LOCATIONS\n",
    "\n",
    "print(\n",
    "    f\"INITIAL_AVG_CARRYING_CAPACITY_PER_LOCATION: {INITIAL_AVG_CARRYING_CAPACITY_PER_LOCATION}\"\n",
    ")\n",
    "\n",
    "BIOMES = [\n",
    "    \"tropical and subtropical moist broadleaf forests\",\n",
    "    \"tropical and subtropical dry broadleaf forests\",\n",
    "    \"tropical and subtropical coniferous forests\",\n",
    "    \"temperate broadleaf and mixed forests\",\n",
    "    \"temperate coniferous forests\",\n",
    "    \"boreal forests/taiga\",\n",
    "    \"tropical and subtropical grasslands, savannas, and shrublands\",\n",
    "    \"temperate grasslands, savannas, and shrublands\",\n",
    "    \"flooded grasslands and savannas\",\n",
    "    \"montane grasslands and shrublands\",\n",
    "    \"tundra\",\n",
    "    \"Mediterranean forests, woodlands, and scrub or sclerophyll forests\",\n",
    "    \"deserts and xeric shrublands\",\n",
    "    \"mangrove\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "biomes = Network(\n",
    "    directed=False,\n",
    "    neighborhood_highlight=False, \n",
    "    select_menu=True, \n",
    "    filter_menu=True,\n",
    "    cdn_resources=\"in_line\"\n",
    ")\n",
    "\n",
    "pre_biomes = nx.Graph()\n",
    "\n",
    "# https://stackoverflow.com/a/47555011/8423001\n",
    "nodes_and_biomes_dict = {node_id: BIOMES[node_id] for node_id in range(len(BIOMES))}\n",
    "\n",
    "pre_biomes.add_nodes_from(\n",
    "    [(node, {\"biome\": attribute}) \n",
    "        for (node, attribute) \n",
    "        in nodes_and_biomes_dict.items()\n",
    "    ] \n",
    ")\n",
    "\n",
    "pre_biomes.add_edges_from(\n",
    "    [\n",
    "        (0, 1),\n",
    "        (0, 2),\n",
    "        (0, 3),\n",
    "        (0, 4),\n",
    "        (0, 6),\n",
    "        (0, 9),\n",
    "        (0, 12),\n",
    "        (0, 13),\n",
    "        (1, 2),\n",
    "        (1, 6),\n",
    "        (1, 8),\n",
    "        (1, 9),\n",
    "        (1, 12),\n",
    "        (1, 13),\n",
    "        (2, 3),\n",
    "        (2, 4),\n",
    "        (2, 6),\n",
    "        (2, 8),\n",
    "        (2, 9),\n",
    "        (2, 12),\n",
    "        (2, 13),\n",
    "        (3, 4),\n",
    "        (3, 5),\n",
    "        (3, 6),\n",
    "        (3, 7),\n",
    "        (3, 8),\n",
    "        (3, 9),\n",
    "        (3, 11),\n",
    "        (3, 12),\n",
    "        (3, 13),\n",
    "        (4, 5),\n",
    "        (4, 6),\n",
    "        (4, 7),\n",
    "        (4, 8),\n",
    "        (4, 9),\n",
    "        (4, 10),\n",
    "        (4, 11),\n",
    "        (4, 12),\n",
    "        (4, 13),\n",
    "        (5, 7),\n",
    "        (5, 8),\n",
    "        (5, 9),\n",
    "        (5, 10),\n",
    "        (6, 7),\n",
    "        (6, 8),\n",
    "        (6, 9),\n",
    "        (6, 12),\n",
    "        (6, 13),\n",
    "        (7, 8),\n",
    "        (7, 9),\n",
    "        (7, 11),\n",
    "        (7, 12),\n",
    "        (8, 9),\n",
    "        (8, 11),\n",
    "        (8, 12),\n",
    "        (8, 13),\n",
    "        (9, 11),\n",
    "        (9, 12),\n",
    "        (9, 13),\n",
    "        (11, 12),\n",
    "        (11, 13),\n",
    "        (12, 13)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biomes.from_nx(nx_graph=pre_biomes)\n",
    "# biomes.show(\"biomes.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = Network(\n",
    "    directed=True,\n",
    "    neighborhood_highlight=True, \n",
    "    select_menu=True, \n",
    "    filter_menu=True,\n",
    "    cdn_resources=\"in_line\"\n",
    ")\n",
    "\n",
    "pre_world = nx.connected_watts_strogatz_graph(\n",
    "    n=NUM_WORLD_LOCATIONS,\n",
    "    k=5,\n",
    "    p=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (v1, v2, weight) in pre_world.edges.data('weight'):\n",
    "    # https://trenton3983.github.io/files/projects/2020-05-21_intro_to_network_analysis_in_python/2020-05-21_intro_to_network_analysis_in_python.html\n",
    "    # https://stackoverflow.com/questions/40128692/networkx-how-to-add-weights-to-an-existing-g-edges\n",
    "\n",
    "    # Here, the weights represent the ease of travelling between nodes.\n",
    "    # A high weight indicates that travel is easy.\n",
    "    pre_world[v1][v2][\"weight\"] = stats.expon.rvs(scale=1)\n",
    "\n",
    "# Make the graph directed to indicate\n",
    "# allowable population movements.\n",
    "pre_world = pre_world.to_directed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip the last row because we only care about\n",
    "# the upper triangle exclusive of th main diagonal\n",
    "# of the adjacency matrix.\n",
    "for v1 in range(NUM_WORLD_LOCATIONS - 1):\n",
    "    for v2 in range(v1 + 1, NUM_WORLD_LOCATIONS):\n",
    "        current_edge_data = pre_world.get_edge_data(v1, v2)\n",
    "        if current_edge_data is None:\n",
    "            # There is no need to update current_weight.\n",
    "            continue\n",
    "\n",
    "        # Extract weight attribute\n",
    "        current_weight = current_edge_data[\"weight\"]\n",
    "        if current_weight < 1:\n",
    "            # Make the ease of travel different\n",
    "            # for one of the edges connecting the same\n",
    "            # pair of nodes to simulate ocean currents.\n",
    "            pre_world[v1][v2][\"weight\"] = stats.expon.rvs(scale=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_world_betweenness_centralities = nx.betweenness_centrality(\n",
    "    G=pre_world,\n",
    "    weight=\"weight\"\n",
    ")\n",
    "\n",
    "pre_biomes_betweenness_centralities = nx.betweenness_centrality(\n",
    "    G=pre_biomes\n",
    ")\n",
    "\n",
    "# Get a node with a maximal betweenness centrality.\n",
    "# This node will hold our starting population.\n",
    "# https://stackoverflow.com/a/280156/8423001\n",
    "starting_node = max(\n",
    "    pre_world_betweenness_centralities, \n",
    "    key=pre_world_betweenness_centralities.get\n",
    ")\n",
    "\n",
    "starting_node_biome_id = max(\n",
    "    pre_biomes_betweenness_centralities, \n",
    "    key=pre_biomes_betweenness_centralities.get\n",
    ")\n",
    "\n",
    "starting_node_biome = BIOMES[starting_node_biome_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0016025641025641025,\n",
       " 0.0018315018315018313,\n",
       " 0.005087505087505087,\n",
       " 0.0066900691900691886,\n",
       " 0.009523809523809525,\n",
       " 0.016427553927553927,\n",
       " 0.016427553927553927,\n",
       " 0.02616503866503866,\n",
       " 0.02849002849002849,\n",
       " 0.033043345543345544,\n",
       " 0.04137159137159137,\n",
       " 0.05237586487586487,\n",
       " 0.14557895807895804]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(pre_biomes_betweenness_centralities.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  1,  4, 10, 13,  9,  7,  5, 11, 12,  0,  2,  8,  7])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/a/3071441/8423001\n",
    "(\n",
    "    stats.rankdata(\n",
    "        a=list(pre_biomes_betweenness_centralities.values()),\n",
    "        method=\"max\"\n",
    "    )\n",
    "    # Because the ranks start at 1 but Python is 0-indexed,\n",
    "    # subtract 1.\n",
    "    - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(list(pre_biomes_betweenness_centralities.values())) <= 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 5, 5, 5])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.rankdata(\n",
    "        a=[-2, 0, 3, 3, 3],\n",
    "        method=\"max\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10, 10,  9, 10, 11, 10,  9, 10, 11, 10, 10,  9, 10, 11,  9,  9,\n",
       "        9, 10, 10, 10, 11,  9, 11, 10, 10, 10, 10, 10, 11,  9, 10,  9, 11,\n",
       "       10,  9, 10, 10, 11, 10, 10, 10, 10, 10,  9, 10, 10,  9, 10,  9,  9,\n",
       "       10, 10, 10,  9,  9, 10, 10, 11, 10, 11, 10, 10, 11,  9,  9, 10, 10,\n",
       "       10, 11, 10,  9, 10,  9, 10,  9,  9,  9, 10, 11, 11, 11,  9,  9, 10,\n",
       "       10, 10,  9, 11, 11, 10, 11, 11, 10,  9, 11, 10,  9, 10, 11])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.binom.rvs(n=2, p=0.5, loc=10, size=100) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlated_ranks(\n",
    "    x_ranks, \n",
    "    num_y_obs\n",
    "):\n",
    "    \"\"\"Given the ranks of observations for some variable X (x_ranks),\n",
    "    return randomly generated ranks \n",
    "    for a desired number of observations of Y.\n",
    "\n",
    "    The ranks for observations of Y are generated such that\n",
    "    the Spearman rank correlation\n",
    "    coefficient between X and Y is high.\n",
    "\n",
    "    Args:\n",
    "        x_ranks: list. This should be non-empty.\n",
    "            The maximum element should be no larger than\n",
    "            the length of the list.\n",
    "        num_y_obs: integer.  This should be at least 2.\n",
    "\n",
    "    Returns:\n",
    "        list. The elements of the returned list correspond to \n",
    "            ranks for observations of Y.  The returned list\n",
    "            should have a length of num_y_obs.\n",
    "    \"\"\"\n",
    "\n",
    "    num_x_obs = len(x_ranks)\n",
    "    y_ranks = []\n",
    "    for x_rank in x_ranks:\n",
    "        # Sample from a PERT distribution\n",
    "        # with most likely value p_most_likely\n",
    "        p_most_likely = (x_rank + 1) / (num_x_obs + 2)\n",
    "\n",
    "        p = PERT(\n",
    "            min_val=0,\n",
    "            ml_val=p_most_likely,\n",
    "            max_val=1\n",
    "        ).rvs(size=1)\n",
    "        # This binomial random variable can be anything from 0\n",
    "        # to num_y_obs.  However, y_ranks should be anything\n",
    "        # between 1 and num_y_obs.\n",
    "        # The minus 1 ensures us that \n",
    "        y_ranks.append(stats.binom.rvs(n=num_y_obs - 1, p=p, size=1).item() + 1)\n",
    "    \n",
    "    return y_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 24, 12, 73, 92, 86]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thingys = get_correlated_ranks(x_ranks=[3, 1.5, 1.5, 4.5, 4.5, 6], num_y_obs=100)\n",
    "thingys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0029185009086060416,\n",
       " 0.0037909003431576094,\n",
       " 0.004687778837438701,\n",
       " 0.005389986682503692,\n",
       " 0.0061083788974945425,\n",
       " 0.006120787753440813,\n",
       " 0.006147235228867882,\n",
       " 0.0066454142984755235,\n",
       " 0.006786613372884244,\n",
       " 0.006825053253624683,\n",
       " 0.006903177218576103,\n",
       " 0.006908970344344496,\n",
       " 0.006998715455734631,\n",
       " 0.008223694695556168,\n",
       " 0.008317136378360868,\n",
       " 0.008683439032851526,\n",
       " 0.009409518423123861,\n",
       " 0.00942326873062804,\n",
       " 0.010669472651538205,\n",
       " 0.011048955854150657,\n",
       " 0.011547843690700828,\n",
       " 0.011826885636409446,\n",
       " 0.01186854557293642,\n",
       " 0.012032453219837265,\n",
       " 0.01232521572657627,\n",
       " 0.013003782561605687,\n",
       " 0.013004273378423036,\n",
       " 0.013099895706574743,\n",
       " 0.013286589724437588,\n",
       " 0.01403749426322092,\n",
       " 0.014635421268074324,\n",
       " 0.01525476516200078,\n",
       " 0.015370910268869449,\n",
       " 0.016635280704544772,\n",
       " 0.01709491177642074,\n",
       " 0.01720553776830832,\n",
       " 0.01764910803253413,\n",
       " 0.017986562327935236,\n",
       " 0.018161114064020673,\n",
       " 0.019257725828535972,\n",
       " 0.019337906876558706,\n",
       " 0.019343233783555364,\n",
       " 0.019583749469340068,\n",
       " 0.019757756616136327,\n",
       " 0.019876358095282026,\n",
       " 0.01992489461568002,\n",
       " 0.02041446436931903,\n",
       " 0.022137538015707458,\n",
       " 0.02256352239345437,\n",
       " 0.02406428233577275,\n",
       " 0.025331870539044316,\n",
       " 0.02547805271985854,\n",
       " 0.02617500344773072,\n",
       " 0.02646993687500799,\n",
       " 0.026648372242064254,\n",
       " 0.02704398432598804,\n",
       " 0.027532951713533028,\n",
       " 0.028433439255950068,\n",
       " 0.028508690397991573,\n",
       " 0.028923586205589914,\n",
       " 0.02999176034117283,\n",
       " 0.030711548352240985,\n",
       " 0.03109896127830575,\n",
       " 0.03182211750548176,\n",
       " 0.0327519127611892,\n",
       " 0.03320856861363973,\n",
       " 0.0336436113646998,\n",
       " 0.03388513957468812,\n",
       " 0.03542466146053035,\n",
       " 0.035513201839732444,\n",
       " 0.035950730137495744,\n",
       " 0.03678114700068936,\n",
       " 0.037193042418769084,\n",
       " 0.03878723203089313,\n",
       " 0.039678874573741606,\n",
       " 0.04029712128042369,\n",
       " 0.041303211092945144,\n",
       " 0.04146394101557985,\n",
       " 0.04221932983528531,\n",
       " 0.04257448328258472,\n",
       " 0.04299907815677761,\n",
       " 0.04356993243820699,\n",
       " 0.04546120351624373,\n",
       " 0.04698928731087049,\n",
       " 0.048608813482035496,\n",
       " 0.050331154335483345,\n",
       " 0.0530409368226313,\n",
       " 0.05338618297801968,\n",
       " 0.05403549758837326,\n",
       " 0.057161599137480396,\n",
       " 0.05997959700804478,\n",
       " 0.06118821969162106,\n",
       " 0.06153182750276132,\n",
       " 0.06172881151236132,\n",
       " 0.06230945638799689,\n",
       " 0.06462378696454148,\n",
       " 0.06547264034895449,\n",
       " 0.07476189778292441,\n",
       " 0.07950829776741959]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We plan on assigning biomes to the nodes in our world.\n",
    "# But, we must consider that some biomes are more likely\n",
    "# to be connected.  Thus, we assign the biomes randomly\n",
    "# while taking account of the betweenness centralities.\n",
    "# With probability 0.5, we assign neighbors the same\n",
    "# biome, while with probability 0.5, we assign neighbors\n",
    "# a new biome of similar betweenness centrality.\n",
    "1.0 / NUM_WORLD_LOCATIONS\n",
    "sorted(pre_biomes_betweenness_centralities.values())\n",
    "# Given a value of the ECDF of pre_world_betweenness_centralities\n",
    "# generate an appropriately positioned random rank\n",
    "# within pre_biomes_betweenness_centralities.\n",
    "# First, rank the pre_world_betweenness_centralities.\n",
    "sorted(pre_world_betweenness_centralities.values())\n",
    "# Second, find the find the value of the ECDF for each rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02331390236461356"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(\n",
    "    a=list(pre_world_betweenness_centralities.values()),\n",
    "    q=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "3\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "for id in pre_biomes.neighbors(starting_node_biome_id):\n",
    "    print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through nodes and set initial parameters.\n",
    "for node in nx.nodes(G=pre_world):\n",
    "    nx.set_node_attributes(\n",
    "        G=pre_world, \n",
    "        values={node: {\"carrying_capacity\": 1000000}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.from_nx(nx_graph=pre_world, show_edge_weights=True)\n",
    "world.show(\"world.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doe_group_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
