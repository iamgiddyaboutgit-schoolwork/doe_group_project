---
title: "Human Population Size on an Earth-like Planet--a Computer Experiment"
authors: "Justin Patterson, Elsa Beda"
output: pdf_document
---

```{r}
library("dplyr")
library("MaxPro")
```

```{r}
DATA_PATH = file.path("/home/justin/Documents/schoolwork/ISYE_6413_Design_of_Exp/doe_group_project/data")
```


```{r}
#####################################################
# Functions
#####################################################
scale_from_0_1 = function(x, rescalings) {
    # Given a matrix x of real numbers,
    # rescale the entries.  Assume that
    # entries in the same column of x
    # should be rescaled in the same way.
    #
    # Args:
    #   x: numeric. matrix with entries in the
    #       interval [0, 1].
    #   rescalings: matrix. It is required that
    #       NROW(rescalings) == NCOL(x).  Each row of 
    #       rescalings should contain a vector
    #       with two entries. The 1st entry
    #       should be the min and the 2nd entry
    #       should be the max for the rescaling
    #       of the column in x corresponding to 
    #       that row.
    #   
    # Returns:
    #   matrix of the same dimensions as x.
    num_x_rows = NROW(x)
    num_x_cols = NCOL(x)
    # To be filled in later . . . .
    rescaled_x = matrix(
        data = numeric(length = num_x_rows * num_x_cols), 
        nrow = num_x_rows, 
        ncol = num_x_cols, 
        byrow = TRUE
    )
    
    # Rescale each column of x.
    for (j in seq_len(num_x_cols)) {
        rescaled_x[, j] = x[, j]*(rescalings[j, 2] - rescalings[j, 1]) + rescalings[j, 1]
    }

    return(rescaled_x)
}

scale_to_0_1 = function(x, rescalings) {
    # Given a matrix x of real numbers,
    # rescale the entries.  Assume that
    # entries in the same column of x
    # should be rescaled in the same way.
    #
    # Args:
    #   x: numeric. matrix.
    #   rescalings: matrix. It is required that
    #       NROW(rescalings) == NCOL(x).  Each row of 
    #       rescalings should contain a vector
    #       with two entries. The 1st entry
    #       should be the min and the 2nd entry
    #       should be the max for the rescaling
    #       of the column in x corresponding to 
    #       that row.
    #   
    # Returns:
    #   matrix of the same dimensions as x.
    num_x_rows = NROW(x)
    num_x_cols = NCOL(x)
    # To be filled in later . . . .
    rescaled_x = matrix(
        data = numeric(length = num_x_rows * num_x_cols), 
        nrow = num_x_rows, 
        ncol = num_x_cols, 
        byrow = TRUE
    )
    
    # Rescale each column of x.
    for (j in seq_len(num_x_cols)) {
        rescaled_x[, j] = (x[, j] - rescalings[j, 1])/(rescalings[j, 2] - rescalings[j, 1])
    }

    return(rescaled_x)
}

# Don't forget to update this as necessary
# as the constraints are hard-coded.
is_valid_treatment_for_ecoregion = function(treatment){ 
    # Initialize everything as TRUE,
    # assuming that everything is going to be valid.
    is_the_trt_valid = rep(TRUE, length(treatment))

    is_the_trt_valid[1] = (treatment[1] >= 1.5*max(treatment[2], treatment[3]))
    is_the_trt_valid[5] = (round(treatment[5], 10) != 0)
    return(all(is_the_trt_valid))
}
```

Read in the factor chart showing the split-plot design and factor constraints.

```{r}
factor_chart = read.csv(
    file = file.path(DATA_PATH, "factor_chart.tsv"),
    header = TRUE,
    sep = "\t"
)

nestings = read.csv(
    file = file.path(DATA_PATH, "ecos.tsv"),
    header = TRUE,
    sep = "\t"
)
```

```{r}
num_factors_for_realms = sum(factor_chart["experimental_unit"] == "realm")
num_factors_for_biome_realm_combos = sum(factor_chart["experimental_unit"] == "biome/realm combo")
num_factors_for_ecoregions = sum(factor_chart["experimental_unit"] == "ecoregion")
```

```{r}
num_realms = NROW(unique(nestings["REALM"]))
num_biomes = NROW(unique(nestings["BIOME_NAME"]))
num_ecoregions = NROW(unique(nestings["ECO_NAME"]))
num_locations = NROW(nestings)

realm_counts = nestings %>% count(REALM)
realm_biome_combos_counts = nestings %>% count(REALM, BIOME_NAME)
biome_counts = nestings %>% count(BIOME_NAME)
ecoregion_counts = nestings %>% count(ECO_NAME)
```

Generate separate designs for each type of factor and then combine them.

```{r}
# The authors of MaxPro recommend that the initial design 
# used in the MaxPro fucntion is generated by the 
# MaxProLHD function.
ecoregions_max_pro_lhd_obj = MaxPro::MaxProLHD(
    n = num_ecoregions,
    p = num_factors_for_ecoregions,
    s = 2,
    itermax = 350,
    total_iter = 1e+03
)

ecoregions_max_pro_lhd = ecoregions_max_pro_lhd_obj[["Design"]]
```

```{r }
ecoregions_max_pro_design_obj = MaxPro::MaxPro(
    InitialDesign = ecoregions_max_pro_lhd,
    s = 2,
    iteration = 3
)

ecoregions_max_pro_design = ecoregions_max_pro_design_obj[["Design"]]
```

Rescale the design.

```{r}
design_for_ecoregions_rescaled = scale_from_0_1(
    x = ecoregions_max_pro_design,
    rescalings = factor_chart %>%
        dplyr::filter(experimental_unit == "ecoregion") %>%
        dplyr::select(min_level, max_level)
)
```

Only take runs from the rescaled design that meet the constraints.

```{r}
valid_runs = apply(
    X = design_for_ecoregions_rescaled,
    MARGIN = 1,
    FUN = is_valid_treatment_for_ecoregion
)

d = design_for_ecoregions_rescaled[valid_runs, ]
```

```{r}
# Rescale back to 0-1
d = scale_to_0_1(
    x = d,
    rescalings = factor_chart %>%
        dplyr::filter(experimental_unit == "ecoregion") %>%
        dplyr::select(min_level, max_level)
)
```

```{r}
# Generate a candidate design meeting the constraints
# that we can pull from.
c = CandPoints(N = 10000, p_cont = num_factors_for_ecoregions)
```

```{r}
# Scale and re-scale to filter.
c = scale_from_0_1(
    x = c,
    rescalings = factor_chart %>%
        dplyr::filter(experimental_unit == "ecoregion") %>%
        dplyr::select(min_level, max_level)
)

valid_runs = apply(
    X = c,
    MARGIN = 1,
    FUN = is_valid_treatment_for_ecoregion
)

c = scale_to_0_1(
    x = c,
    rescalings = factor_chart %>%
        dplyr::filter(experimental_unit == "ecoregion") %>%
        dplyr::select(min_level, max_level)
)

c = c[valid_runs, ]
```

```{r}
# Calculate the number of new points needed.
new_needed = num_ecoregions - NROW(d)
```

```{r}
# Get more points
d_obj = MaxProAugment(
    ExistDesign = d, 
    CandDesign = c, 
    nNew = new_needed
)
```

```{r}
d = d_obj[["Design"]]
d = scale_from_0_1(
    x = d,
    rescalings = factor_chart %>%
        dplyr::filter(experimental_unit == "ecoregion") %>%
        dplyr::select(min_level, max_level)
)
```



```{r}
# Check
all(
    apply(
        X = d,
        MARGIN = 1,
        FUN = is_valid_treatment_for_ecoregion
    )
) 
```

```{r}
design_for_realms = minimax(
    N = num_realms,
    p = num_factors_for_realms,
    region = "hypercube"
)
```



Don't forget to repeat the rows as necessary to
account for the split-plot design.

```{r}
# Initialize
num_rows = num_locations
num_cols = NCOL(design_for_realms_rescaled)
design_for_realms_rescaled_repeated = matrix(
    data = numeric(length = num_rows * num_cols),
    nrow = num_rows,
    ncol = num_cols
)
row_repeats_used = 0
# Put entries into design_for_realms_rescaled_repeated
for (i in seq_len(num_realms)) {
    row_repeats_needed = realm_counts[i, "n", drop = TRUE]
    if (row_repeats_needed == 0){
        next
    }
    design_for_realms_rescaled_repeated[row_repeats_used + seq.int(row_repeats_needed), ] = design_for_realms_rescaled[
        rep(i, times = row_repeats_needed), 
        # all cols
    ]
    row_repeats_used = row_repeats_used + row_repeats_needed 
}
```

```{r}
design_for_ecoregions = minimax(
    N = num_ecoregions,
    p = num_factors_for_ecoregions,
    region = "ineq",
    const = is_valid_treatment_for_ecoregion
)
```

```{r}
# Get day of the week.
cmd = "date"
my_field = 1
system2(cmd, args = paste0(' | cut -f ', my_field, ' -d " "'))
```

```{r}
system2(
    command = "python", 
    args = "-V", 
    stdout = TRUE,
    stderr = FALSE
)
```